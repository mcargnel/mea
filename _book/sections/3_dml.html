<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Double Machine Learning – Double Machine Learning for Difference in Difference: Fundamentals and Application</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../sections/4_application.html" rel="next">
<link href="../sections/2_did.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-626149efe8f5d16e1d391ba177679bf0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../sections/3_dml.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Double Machine Learning</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Double Machine Learning for Difference in Difference: Fundamentals and Application</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/1_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/2_did.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Difference in Differences</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/3_dml.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Double Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/4_application.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Application</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#framework" id="toc-framework" class="nav-link active" data-scroll-target="#framework"><span class="header-section-number">3.1</span> Framework</a>
  <ul class="collapse">
  <li><a href="#the-goal-estimating-the-average-treatment-effect-ate" id="toc-the-goal-estimating-the-average-treatment-effect-ate" class="nav-link" data-scroll-target="#the-goal-estimating-the-average-treatment-effect-ate"><span class="header-section-number">3.1.1</span> The Goal: Estimating the Average Treatment Effect (ATE)</a></li>
  <li><a href="#the-problem-confounding-bias" id="toc-the-problem-confounding-bias" class="nav-link" data-scroll-target="#the-problem-confounding-bias"><span class="header-section-number">3.1.2</span> The Problem: Confounding Bias</a></li>
  <li><a href="#the-theoretical-solution-orthogonalization" id="toc-the-theoretical-solution-orthogonalization" class="nav-link" data-scroll-target="#the-theoretical-solution-orthogonalization"><span class="header-section-number">3.1.3</span> The Theoretical Solution: Orthogonalization</a></li>
  <li><a href="#the-practical-implementation-double-machine-learning" id="toc-the-practical-implementation-double-machine-learning" class="nav-link" data-scroll-target="#the-practical-implementation-double-machine-learning"><span class="header-section-number">3.1.4</span> The Practical Implementation: Double Machine Learning</a></li>
  <li><a href="#addressing-machine-learning-biases-for-valid-inference" id="toc-addressing-machine-learning-biases-for-valid-inference" class="nav-link" data-scroll-target="#addressing-machine-learning-biases-for-valid-inference"><span class="header-section-number">3.1.5</span> Addressing Machine Learning Biases for Valid Inference</a></li>
  </ul></li>
  <li><a href="#dml-for-did" id="toc-dml-for-did" class="nav-link" data-scroll-target="#dml-for-did"><span class="header-section-number">3.2</span> DML for DID</a></li>
  <li><a href="#dml-for-staggered-did" id="toc-dml-for-staggered-did" class="nav-link" data-scroll-target="#dml-for-staggered-did"><span class="header-section-number">3.3</span> DML for Staggered DID</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Double Machine Learning</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Over the years, Machine Learning approaches were relegated to prediction tasks. Mainly becuase of their flexibility, they achieve great predictive performance for high dimensional datasets. But when it comes to interpretation, which is what usually economists and social scientists look for, then is not that helpful because interpretation and finding causal relationships is the key. In that regard, interpretable machine learning could be considered an intermediate point, whith a battery of methods for interpreting the complex machine learning algortihms results. A great review of these methods can be found in <span class="citation" data-cites="molnar2025">(<a href="references.html#ref-molnar2025" role="doc-biblioref">Molnar, 2025</a>)</span>, but in reality they are very much tied to correlations and not to understand causal relationships.</p>
<p>That’s why a new framework was introduced by <span class="citation" data-cites="Chernozhukov_2018">(<a href="references.html#ref-Chernozhukov_2018" role="doc-biblioref">Chernozhukov et al., 2018</a>)</span> where using Frish Waigh Lovell theorem end up using the flexibility of machine learning models for estimating causal relationships. In this chapter, I’ll introduce the framework more formally and then present how to apply it for differences in differences including the extension to staggered.</p>
<section id="framework" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="framework"><span class="header-section-number">3.1</span> Framework</h2>
<section id="the-goal-estimating-the-average-treatment-effect-ate" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="the-goal-estimating-the-average-treatment-effect-ate"><span class="header-section-number">3.1.1</span> The Goal: Estimating the Average Treatment Effect (ATE)</h3>
<p>The primary goal is to estimate the causal effect of a treatment <span class="math inline">\(D\)</span> on an outcome <span class="math inline">\(Y\)</span>, controlling for a set of covariates <span class="math inline">\(X\)</span>. We assume a constant treatment effect, <span class="math inline">\(\theta\)</span>, which represents the Average Treatment Effect (ATE). <span class="math display">\[
ATE = E[Y_i(1)-Y_i(0)]
\]</span></p>
<p>Where <span class="math inline">\(Y_i(1)\)</span> is the potential outcome for unit <span class="math inline">\(i\)</span> if treated, and <span class="math inline">\(Y_i(0)\)</span> is the potential outcome if untreated. The fundamental problem of causal inference is that we can only observe one of these potential outcomes for each unit.</p>
<p>To model this, we use a <strong>Partially Linear Model (PLM)</strong>, which is a common setup for DML:</p>
<p><span class="math display">\[
\begin{aligned}
Y_i &amp;= \theta D_i + g(X_i) + \epsilon_i \quad \text{(Outcome Model)} \\
D_i &amp;= m(X_i) + u_i \quad \text{(Treatment Model)}
\end{aligned}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(Y_i\)</span> is the observed outcome.</li>
<li><span class="math inline">\(D_i\)</span> is the observed treatment status (e.g., 1 if treated, 0 if not).</li>
<li><span class="math inline">\(X_i\)</span> is a vector of covariates.</li>
<li><span class="math inline">\(\theta\)</span> is the causal parameter of interest (the ATE, assuming a constant effect).</li>
<li><span class="math inline">\(g(X_i)\)</span> and <span class="math inline">\(m(X_i)\)</span> are unknown, potentially complex functions, known as “nuisance functions”, that represent how the covariates <span class="math inline">\(X\)</span> affect the outcome and the treatment, respectively.</li>
<li><span class="math inline">\(\epsilon_i\)</span> and <span class="math inline">\(u_i\)</span> are error terms, which we assume are exogenous (i.e., <span class="math inline">\(E[\epsilon_i|X_i, D_i] = 0\)</span> and <span class="math inline">\(E[u_i|X_i] = 0\)</span>).</li>
</ul>
</section>
<section id="the-problem-confounding-bias" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="the-problem-confounding-bias"><span class="header-section-number">3.1.2</span> The Problem: Confounding Bias</h3>
<p>We cannot simply estimate <span class="math inline">\(\theta\)</span> by regressing <span class="math inline">\(Y\)</span> on <span class="math inline">\(D\)</span>. The covariates <span class="math inline">\(X\)</span> introduce confounding bias (a form of omitted variable bias) because they affect <em>both</em> the treatment <span class="math inline">\(D\)</span> (via <span class="math inline">\(m(X)\)</span>) and the outcome <span class="math inline">\(Y\)</span> (via <span class="math inline">\(g(X)\)</span>).</p>
<p>We can visualize this confounding path using a Directed Acyclic Graph (DAG):</p>
<p>To get an unbiased estimate of <span class="math inline">\(\theta\)</span>, we must “control for” or “partial out” the influence of <span class="math inline">\(X\)</span>.</p>
</section>
<section id="the-theoretical-solution-orthogonalization" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="the-theoretical-solution-orthogonalization"><span class="header-section-number">3.1.3</span> The Theoretical Solution: Orthogonalization</h3>
<p>The DML framework builds on the <strong>Frisch-Waugh-Lovell (FWL) theorem</strong>. The theorem shows how to estimate a parameter in a multivariate regression by first residualizing all variables. We can apply this logic to our PLM.</p>
<p>The goal is to find an estimating equation for <span class="math inline">\(\theta\)</span> that is no longer dependent on the nuisance functions <span class="math inline">\(g(X)\)</span> and <span class="math inline">\(m(X)\)</span>. We can derive this by “partialling out” <span class="math inline">\(X\)</span> from <span class="math inline">\(Y\)</span> and <span class="math inline">\(D\)</span>.</p>
<p>Start with the outcome model: <span class="math inline">\(Y_i = \theta D_i + g(X_i) + \epsilon_i\)</span> and take the conditional expectation of <span class="math inline">\(Y_i\)</span> given <span class="math inline">\(X_i\)</span>:</p>
<p><span class="math display">\[
E[Y_i|X_i] = E[\theta D_i + g(X_i) + \epsilon_i | X_i]
\]</span> Assuming <span class="math inline">\(E[\epsilon_i|X_i]=0\)</span> and since <span class="math inline">\(g(X_i)\)</span> is a function of <span class="math inline">\(X_i\)</span>, <span class="math inline">\(E[g(X_i)|X_i] = g(X_i)\)</span>: <span class="math display">\[
E[Y_i|X_i] = \theta E[D_i|X_i] + g(X_i)
\]</span></p>
<p>This gives us an expression for the confounder <span class="math inline">\(g(X_i)\)</span>: <span class="math display">\[
g(X_i) = E[Y_i|X_i] - \theta E[D_i|X_i]
\]</span></p>
<p>Now, substitute this expression for <span class="math inline">\(g(X_i)\)</span> back into the original outcome model:</p>
<p><span class="math display">\[
Y_i = \theta D_i + (E[Y_i|X_i] - \theta E[D_i|X_i]) + \epsilon_i
\]</span></p>
<p>Finally, rearrange the terms to isolate <span class="math inline">\(Y\)</span> and <span class="math inline">\(D\)</span> from their conditional expectations:</p>
<p><span class="math display">\[
Y_i - E[Y_i|X_i] = \theta(D_i - E[D_i|X_i]) + \epsilon_i
\]</span></p>
<p>Let’s define our residuals: <span class="math inline">\(\tilde{Y}_i = Y_i - E[Y_i|X_i]\)</span> (The “residualized” outcome) and <span class="math inline">\(\tilde{D}_i = D_i - E[D_i|X_i]\)</span> (The “residualized” treatment). Then our equation becomes:</p>
<p><span class="math display">\[
\tilde{Y}_i = \theta \tilde{D}_i + \epsilon_i
\]</span></p>
<p>This is the key insight. We have transformed the complex PLM into a simple linear regression. If we could get the <em>true</em> residuals <span class="math inline">\(\tilde{Y}_i\)</span> and <span class="math inline">\(\tilde{D}_i\)</span>, we could estimate <span class="math inline">\(\theta\)</span> without bias using a simple regression of <span class="math inline">\(\tilde{Y}\)</span> on <span class="math inline">\(\tilde{D}\)</span>.</p>
</section>
<section id="the-practical-implementation-double-machine-learning" class="level3" data-number="3.1.4">
<h3 data-number="3.1.4" class="anchored" data-anchor-id="the-practical-implementation-double-machine-learning"><span class="header-section-number">3.1.4</span> The Practical Implementation: Double Machine Learning</h3>
<p>In reality, we do not know the true conditional expectation functions <span class="math inline">\(E[Y|X]\)</span> and <span class="math inline">\(E[D|X]\)</span>. The innovation of <strong>Double Machine Learning</strong> is to use flexible, high-performance machine learning models to estimate them.</p>
<p>So, let <span class="math inline">\(\hat{l}(X_i)\)</span> be an ML-based estimate of <span class="math inline">\(E[Y_i|X_i]\)</span> that we can estimate as a standard <strong>regression</strong> task (since <span class="math inline">\(Y\)</span> is often continuous) and let <span class="math inline">\(\hat{m}(X_i)\)</span> be an ML-based estimate of <span class="math inline">\(E[D_i|X_i]\)</span> that is usually estimated as a <strong>classification</strong> task given that <span class="math inline">\(D\)</span> is binary. In this case <span class="math inline">\(\hat{m}(X_i)\)</span> is an estimate of the propensity score, <span class="math inline">\(P(D_i=1|X_i)\)</span>.</p>
<p>This is the “double” in DML: we use machine learning to estimate the nuisance functions for <em>both</em> the outcome and the treatment models. We can use any suitable ML model, such as Random Forests, Gradient Boosting Machines, or Neural Networks.</p>
<p>We then compute the estimated residuals:</p>
<p><span class="math display">\[
\hat{Y}_i = Y_i - \hat{l}(X_i)
\quad \text{and} \quad
\hat{D}_i = D_i - \hat{m}(X_i)
\]</span></p>
<p>And finally, we estimate <span class="math inline">\(\theta\)</span> using the simple linear regression: <span class="math display">\[
\hat{Y}_i = \theta \hat{D}_i + \hat{\epsilon}_i
\]</span></p>
</section>
<section id="addressing-machine-learning-biases-for-valid-inference" class="level3" data-number="3.1.5">
<h3 data-number="3.1.5" class="anchored" data-anchor-id="addressing-machine-learning-biases-for-valid-inference"><span class="header-section-number">3.1.5</span> Addressing Machine Learning Biases for Valid Inference</h3>
<p>Using flexible ML models to estimate nuisance functions introduces two main statistical challenges that could invalidate our final estimate of <span class="math inline">\(\theta\)</span>: <strong>overfitting bias</strong> and <strong>estimation bias</strong> (e.g., from regularization). The DML framework employs two crucial techniques to solve these problems and ensure our final estimate is statistically valid.</p>
<section id="cross-fitting-solving-overfitting-bias" class="level4" data-number="3.1.5.1">
<h4 data-number="3.1.5.1" class="anchored" data-anchor-id="cross-fitting-solving-overfitting-bias"><span class="header-section-number">3.1.5.1</span> Cross-Fitting: Solving Overfitting Bias</h4>
<p>If we use the same data observations to <em>train</em> the ML models (<span class="math inline">\(\hat{l}\)</span> and <span class="math inline">\(\hat{m}\)</span>) and to <em>estimate</em> the final parameter <span class="math inline">\(\theta\)</span>, our estimate will be biased. This is a form of overfitting, where the generated residuals (<span class="math inline">\(\hat{Y}_i, \hat{D}_i\)</span>) would have a spurious correlation simply because the model was optimized using those same <span class="math inline">\(Y_i\)</span> and <span class="math inline">\(D_i\)</span> values. The solution is <strong>cross-fitting</strong> (or <em>sample splitting</em>). This procedure ensures that the residuals for any given observation are generated by a model that was <em>not</em> trained on that same observation. This “breaks” the overfitting link.</p>
<p>While <em>K-fold</em> cross-fitting is standard, the process is easiest to understand with a 2-fold split:</p>
<ol type="1">
<li><strong>Split:</strong> Randomly partition the dataset into two equal halves (e.g., Fold 1 and Fold 2).</li>
<li><strong>Train on Fold 1, Predict on Fold 2:</strong>
<ul>
<li>Train the ML models <span class="math inline">\(\hat{l}_1\)</span> and <span class="math inline">\(\hat{m}_1\)</span> using <em>only</em> the data in Fold 1.</li>
<li>Use these trained models to generate residuals (<span class="math inline">\(\hat{Y}_i = Y_i - \hat{l}_1(X_i)\)</span>, <span class="math inline">\(\hat{D}_i = D_i - \hat{m}_1(X_i)\)</span>) for the data in <strong>Fold 2</strong>.</li>
</ul></li>
<li><strong>Train on Fold 2, Predict on Fold 1:</strong>
<ul>
<li>Train <em>new</em> models <span class="math inline">\(\hat{l}_2\)</span> and <span class="math inline">\(\hat{m}_2\)</span> using <em>only</em> the data in Fold 2.</li>
<li>Use these models to generate the residuals for the data in <strong>Fold 1</strong>.</li>
</ul></li>
<li><strong>Estimate:</strong> Combine the residuals generated in step 2 (for Fold 2) and step 3 (for Fold 1) into one complete dataset.</li>
<li>Run the final, simple OLS regression <span class="math inline">\(\hat{Y}_i = \theta \hat{D}_i + \hat{\epsilon}_i\)</span> on this combined set of residuals to get the single, unbiased estimate of <span class="math inline">\(\theta\)</span>.</li>
</ol>
</section>
<section id="neyman-orthogonality-solving-estimation-bias" class="level4" data-number="3.1.5.2">
<h4 data-number="3.1.5.2" class="anchored" data-anchor-id="neyman-orthogonality-solving-estimation-bias"><span class="header-section-number">3.1.5.2</span> Neyman Orthogonality: Solving Estimation Bias</h4>
<p>ML models (like Random Forest or Lasso) are designed for optimal <em>prediction</em>, not for unbiasedly estimating the <em>true</em> functions <span class="math inline">\(l(X)\)</span> and <span class="math inline">\(m(X)\)</span>. Their estimates, <span class="math inline">\(\hat{l}\)</span> and <span class="math inline">\(\hat{m}\)</span>, will inevitably contain some “estimation bias” (e.g., from regularization). We must ensure that this bias in our nuisance function estimates does not “contaminate” or “leak into” our final estimate of <span class="math inline">\(\theta\)</span>.</p>
<p>The solution lies in the <em>structure</em> of our final estimating equation: <span class="math inline">\(\tilde{Y}_i = \theta \tilde{D}_i + \epsilon_i\)</span>. This specific equation, derived from the FWL theorem, possesses a critical property known as <strong>Neyman Orthogonality</strong>.</p>
<p>This property means that the final estimate of <span class="math inline">\(\theta\)</span> is <em>first-order insensitive</em> to small errors or biases in the estimation of the nuisance functions <span class="math inline">\(l(X)\)</span> and <span class="math inline">\(m(X)\)</span>. Because we have residualized <em>both</em> <span class="math inline">\(Y\)</span> (which depends on <span class="math inline">\(l(X)\)</span>) and <span class="math inline">\(D\)</span> (which depends on <span class="math inline">\(m(X)\)</span>), the estimation errors in <span class="math inline">\(\hat{l}\)</span> and <span class="math inline">\(\hat{m}\)</span> effectively cancel each other out, leaving our estimate of <span class="math inline">\(\theta\)</span> asymptotically unbiased.</p>
<p>This orthogonality is the key theoretical property that allows DML to work: it permits us to use “imperfect” but powerful ML models for the complex prediction tasks, while still achieving a statistically valid (unbiased and asymptotically normal) estimate for our single causal parameter of interest, <span class="math inline">\(\theta\)</span>.</p>
</section>
</section>
</section>
<section id="dml-for-did" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="dml-for-did"><span class="header-section-number">3.2</span> DML for DID</h2>
<p>This framework can be adapted for Difference-in-Differences (DID) settings, where we want to estimate the Average Treatment Effect on the Treated (ATT) in a panel data context with treatment and control groups over time. In this section we will show how can be used when treatments occur at the same time and in the next one we will be extending that case for the staggered case (e.g.&nbsp;when treatments can occur at different times). For the more simple scenario, we will be following (<span class="citation" data-cites="chang_2020">Chang (<a href="references.html#ref-chang_2020" role="doc-biblioref">2020</a>)</span>), where it proposed an adjustment to create a score function that is Neyman-Orthogonal. In essence, the paper proposed:</p>
<p>Given <span class="math inline">\(Y_{i0}\)</span> the pre-treatment outcome, <span class="math inline">\(Y_{i1}\)</span> the post-treatment outcome, <span class="math inline">\(D_i\)</span> the treatment indicator and a vector of covariates <span class="math inline">\(X_i\)</span> we need to calculate <span class="math inline">\(\psi_i\)</span> using the following Neyman Orthogonal formula:</p>
<p><span class="math display">\[
\psi_i = \frac{D_i-E[D=1|X]}{E[D](1-(E[D=1|X]))}[(Y_{i1}-Y_{i0})-E[Y_{i1}-Y_{i0}|D=0,X]]
\]</span></p>
<p>Once we’ve have this score, we simply need to take the average across observations for the <span class="math inline">\(\psi_i\)</span> <span class="math display">\[
\hat \psi = \frac{1}{n} \sum_{i=1}^n \psi_i
\]</span></p>
<p>Now, if we want to analize the calculation of <span class="math inline">\(\psi_i\)</span>: the first key part is the “Residualized Outcome Change”: <span class="math inline">\((Y_{i1} - Y_{i0}) - E[Y_{i1} - Y_{i0} | D=0, X]\)</span>. Here, <span class="math inline">\((Y_{i1} - Y_{i0})\)</span> is the observed change in the outcome for unit <span class="math inline">\(i\)</span>. The second term, <span class="math inline">\(E[Y_{i1} - Y_{i0} | D=0, X]\)</span>, is the nuisance function for the outcome. It’s our best machine-learning-based prediction of the outcome change that a unit with covariates <span class="math inline">\(X\)</span> would have experienced if it were in the control group <span class="math inline">\((D=0)\)</span>. The entire term thus represents the “unexplained” change in <span class="math inline">\(Y\)</span>. For a treated unit, this is their observed change minus the change we would have expected based on “parallel trends” derived from the control group with similar <span class="math inline">\(X\)</span>.</p>
<p>The second key part is the “Weighting Term”: <span class="math inline">\((D_i - E[D=1|X]) / (E[D] * (1 - E[D=1|X]))\)</span>. This is the “doubly-robust” weight. It relies on the other two nuisance functions: <span class="math inline">\(E[D=1|X]\)</span>, which is the propensity score (the probability of unit i receiving treatment, given its covariates <span class="math inline">\(X\)</span>), and <span class="math inline">\(E[D]\)</span>, which is the unconditional probability of treatment (estimated as the sample average of <span class="math inline">\(D_i\)</span>). This term re-weights the control group to look like the treated group and ensures the entire score is Neyman-orthogonal.</p>
<p>By multiplying these two terms together and averaging them across all observations, we get a high-quality, doubly-robust estimate of the ATT.</p>
<p>To ensure this works properly and to prevent overfitting, the “nuisance functions” must be estimated using cross-fitting. These functions are: <span class="math inline">\(E[D=1|X]\)</span>, <span class="math inline">\(E[D]\)</span>, and <span class="math inline">\(E[Y_{i1} - Y_{i0} | D=0, X]\)</span>. Cross-fitting involves splitting the data into several “folds,” using some folds to train the machine learning models and other folds to calculate the <span class="math inline">\(psi_i\)</span> scores for the observations that were not used in training.</p>
</section>
<section id="dml-for-staggered-did" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="dml-for-staggered-did"><span class="header-section-number">3.3</span> DML for Staggered DID</h2>
<p>As mentioned before, this framework can be extended to settings when the treatment occurs in different periods for different groups. For example groups that a adopt a policy in different years. For solving the issues commented in the previous chapter, we will be following (<span class="citation" data-cites="callway_santana_2021">Callaway &amp; Santa’Anna (<a href="references.html#ref-callway_santana_2021" role="doc-biblioref">2021</a>)</span>) where they proposed a doubly roboust estimator <span class="math inline">\(ATT_{g,t}\)</span> with <span class="math inline">\(g\)</span> the first period when an unit was treated and <span class="math inline">\(t\)</span> the any post-treatment period. With that, they basically compare the treated units against non treated (including not-yet treated) for each <span class="math inline">\(g\)</span>. Because we will have multiple <span class="math inline">\(g\)</span>, we will ended up with multiple estimations for <span class="math inline">\(ATT_{g,t}\)</span> that we will need to aggregate afterwards for getting the <span class="math inline">\(\hat{ATT}\)</span>.</p>
<p>More formally we can define the <span class="math inline">\(\hat{ATT}\)</span> as</p>
<p><span class="math display">\[
\hat{ATT} = \sum_{g,t} w_{g,t} ATT(g,t)
\]</span></p>
<p>with <span class="math inline">\(w_{g,t}=\frac{N_g,t}{\sum_{g',t'}N_{g',t'}}\)</span> being the weights that reflects the groups sized. For estimating <span class="math inline">\(ATT(g,t)\)</span> the authors proposed</p>
<p><span class="math display">\[
\begin{aligned}
\text{ATT}(g, t) &amp;= \frac{1}{n_g} \sum_{i: G_g = 1} ( Y_{it} - E[Y_t-Y_1|D=0,X] )\\ &amp;- \sum_{i: C = 1} \frac{E[D=1|X]}{1 - E[D=1|X]} ( Y_{it} - E[Y_t-Y_1|D=0,X])
\end{aligned}
\]</span></p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list" style="display: none">
<div id="ref-callway_santana_2021" class="csl-entry" role="listitem">
Callaway, B., &amp; Santa’Anna, P. H. C. (2021). Difference-in-differences with multiple time periods. <em>Journal of Econometrics</em>, <em>225</em>(2), 200–230. <a href="https://doi.org/10.1016/j.jeconom.2020.12.001">https://doi.org/10.1016/j.jeconom.2020.12.001</a>
</div>
<div id="ref-chang_2020" class="csl-entry" role="listitem">
Chang, N.-C. (2020). Double/debiased machine learning for difference-in-differences models. <em>The Econometrics Journal</em>, <em>23</em>(2), 177–191. <a href="https://doi.org/10.1093/ectj/utaa001">https://doi.org/10.1093/ectj/utaa001</a>
</div>
<div id="ref-Chernozhukov_2018" class="csl-entry" role="listitem">
Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., &amp; Robins, J. (2018). Double/debiased machine learning for treatment and structural parameters. <em>The Econometrics Journal</em>, <em>21</em>(1), C1–C68. <a href="https://doi.org/10.1111/ectj.12097">https://doi.org/10.1111/ectj.12097</a>
</div>
<div id="ref-molnar2025" class="csl-entry" role="listitem">
Molnar, C. (2025). <em>Interpretable machine learning: A guide for making black box models explainable</em> (3rd ed.). Retrieved from <a href="https://christophm.github.io/interpretable-ml-book">https://christophm.github.io/interpretable-ml-book</a>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../sections/2_did.html" class="pagination-link" aria-label="Difference in Differences">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Difference in Differences</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../sections/4_application.html" class="pagination-link" aria-label="Application">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Application</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>